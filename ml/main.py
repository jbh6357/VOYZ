"""
FastAPI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
íŠ¹ì¼ ë§¤ì¹­ API ì„œë²„
"""

from fastapi import FastAPI, HTTPException, File, UploadFile
from typing import Dict, Any, List
from datetime import datetime

# ì„¤ì • ë° ëª¨ë¸ import
from config import API_CONFIG, SpecialDayMatchRequest, ContentGenerationRequest, CategoryClassificationRequest, CreateSuggestRequest, CreateSuggestResponse
from models.match_models import MatchModels
from services.content_service import ContentService
from services.category_service import CategoryService
import os
from dotenv import load_dotenv
from google.cloud import vision
import re
from google.cloud import translate_v2 as translate
from config import MenuItem, TranslateRequest, TranslateRequest2, ReviewTranslateRequest
from typing import List
import math
from collections import Counter
import re as _re
import json as _json
import requests

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title=API_CONFIG["title"],
    version=API_CONFIG["version"],
    description=API_CONFIG["description"]
)
@app.post("/api/reviews/summary")
def generate_review_summary(payload: dict):
    """
    ë©”ë‰´ë³„ ë¦¬ë·° í•œì¤„ í‰ ìƒì„±
    ìš”ì²­: {
      "menuName": str,
      "reviews": [{"text": str, "sentiment": str}],  # sentiment: "positive", "neutral", "negative"
      "prioritySentiment": str  # "positive", "neutral", "negative" ìš°ì„ ìˆœìœ„
    }
    ì‘ë‹µ: {
      "summary": str,
      "basedOnSentiment": str,
      "reviewCount": int
    }
    """
    menu_name = payload.get("menuName", "ë©”ë‰´")
    reviews = payload.get("reviews", [])
    priority_sentiment = payload.get("prioritySentiment", "positive")
    
    if not reviews:
        return {
            "summary": "ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤",
            "basedOnSentiment": priority_sentiment,
            "reviewCount": 0
        }
    
    # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë¦¬ë·° í•„í„°ë§
    target_reviews = [r for r in reviews if r.get("sentiment") == priority_sentiment]
    
    # ìš°ì„ ìˆœìœ„ ê°ì •ì˜ ë¦¬ë·°ê°€ ì—†ìœ¼ë©´ ì „ì²´ ë¦¬ë·° ì‚¬ìš©
    if not target_reviews:
        target_reviews = reviews
        priority_sentiment = "mixed"
    
    # OpenAI APIë¡œ í•œì¤„ í‰ ìƒì„±
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        # ë”ë¯¸ ë°ì´í„° ë°˜í™˜
        sentiment_words = {
            "positive": "ë§›ì´ ì¢‹ë‹¤ëŠ” í‰ê°€",
            "neutral": "ë¬´ë‚œí•˜ë‹¤ëŠ” í‰ê°€", 
            "negative": "ì•„ì‰½ë‹¤ëŠ” í‰ê°€",
            "mixed": "ë‹¤ì–‘í•œ ì˜ê²¬"
        }
        return {
            "summary": f"{menu_name}ì— ëŒ€í•´ {sentiment_words.get(priority_sentiment, 'ë‹¤ì–‘í•œ ì˜ê²¬')}ê°€ ìˆìŠµë‹ˆë‹¤",
            "basedOnSentiment": priority_sentiment,
            "reviewCount": len(target_reviews)
        }
    
    try:
        # ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ê¸¸ì´ ì œí•œ
        review_texts = [r.get("text", "")[:100] for r in target_reviews[:10]]  # ìµœëŒ€ 10ê°œ, ê° 100ì
        
        prompt = f"""ë‹¤ìŒ {menu_name}ì— ëŒ€í•œ ë¦¬ë·°ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í•œì¤„ í‰ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë¦¬ë·°ë“¤:
{' / '.join(review_texts)}

ì¡°ê±´:
1. 15ì ì´ë‚´ë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ
2. ê³ ê°ë“¤ì˜ ê³µí†µ ì˜ê²¬ì„ ë°˜ì˜
3. ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í‘œí˜„ ì‚¬ìš©
4. "ë§›ìˆì–´ìš”", "ì–‘ì´ ë§ë„¤ìš”", "ê°€ê²©ì´ í•©ë¦¬ì ", "ì¡°ê¸ˆ ì§œìš”" ë“± ì¼ìƒì  í‘œí˜„
5. "~ë‹¤ëŠ” í‰ê°€", "~í•˜ê³  ìˆë‹¤" ê°™ì€ ë”±ë”±í•œ í‘œí˜„ ê¸ˆì§€

í•œì¤„ í‰:"""

        headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
        data = {
            "model": "gpt-4o-mini",
            "messages": [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë¦¬ë·°ë¥¼ ìš”ì•½í•´ì£¼ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°„ë‹¨í•˜ê³  ê°ê´€ì ì¸ í•œì¤„ í‰ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.3,
            "max_tokens": 50
        }
        
        resp = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=data, timeout=30)
        if resp.status_code == 200:
            content = resp.json()["choices"][0]["message"]["content"].strip()
            
            return {
                "summary": content[:50],  # ìµœëŒ€ 50ìë¡œ ì œí•œ
                "basedOnSentiment": priority_sentiment,
                "reviewCount": len(target_reviews)
            }
            
    except Exception as e:
        print(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
    
    # ì‹¤íŒ¨ì‹œ ë”ë¯¸ ë°ì´í„° ë°˜í™˜
    sentiment_words = {
        "positive": "ì¢‹ë‹¤ëŠ” í‰ê°€",
        "neutral": "ë¬´ë‚œí•˜ë‹¤ëŠ” í‰ê°€", 
        "negative": "ì•„ì‰½ë‹¤ëŠ” í‰ê°€",
        "mixed": "ë‹¤ì–‘í•œ ì˜ê²¬"
    }
    return {
        "summary": f"{sentiment_words.get(priority_sentiment, 'ë‹¤ì–‘í•œ ì˜ê²¬')}ê°€ ìˆìŠµë‹ˆë‹¤",
        "basedOnSentiment": priority_sentiment,
        "reviewCount": len(target_reviews)
    }

@app.post("/api/reviews/content-analysis")
def analyze_review_content(payload: dict):
    """
    ë©”ë‰´ë³„ ë¦¬ë·° ë‚´ìš© ë¶„ì„ - ê¸ì •/ë¶€ì • ë¦¬ë·°ì˜ êµ¬ì²´ì ì¸ ì´ìœ  ì¶”ì¶œ
    ìš”ì²­: {
      "menuName": str,
      "reviews": [{"text": str, "sentiment": str, "rating": int}],
      "prioritySentiment": str
    }
    ì‘ë‹µ: {
      "insight": str,  # "ë§›ì´ ì¢‹ê³  ì–‘ì´ ë§ë‹¤ëŠ” í‰ê°€"
      "keywords": [str]  # ["ë§›", "ì–‘", "ê°€ì„±ë¹„"]
    }
    """
    print("ğŸ” ML ì„œë¹„ìŠ¤: content-analysis ìš”ì²­ ë°›ìŒ")
    print(f"  - payload: {payload}")
    
    menu_name = payload.get("menuName", "ë©”ë‰´")
    reviews = payload.get("reviews", [])
    priority_sentiment = payload.get("prioritySentiment", "positive")
    
    print(f"ğŸ“‹ ML ì„œë¹„ìŠ¤: ë©”ë‰´ëª…={menu_name}, ë¦¬ë·°ìˆ˜={len(reviews)}, ìš°ì„ ê°ì •={priority_sentiment}")
    for i, review in enumerate(reviews[:3]):  # ì²˜ìŒ 3ê°œë§Œ ë¡œê·¸
        print(f"  ğŸ“ ë¦¬ë·° {i+1}: {review.get('text', '')[:50]}... (ê°ì •: {review.get('sentiment', '')}, í‰ì : {review.get('rating', '')})")
    
    if not reviews:
        print("âŒ ML ì„œë¹„ìŠ¤: ë¦¬ë·°ê°€ ì—†ìŒ")
        return {"insight": "ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤", "keywords": []}
    
    # ìš°ì„ ìˆœìœ„ ê°ì •ì˜ ë¦¬ë·°ë§Œ í•„í„°ë§
    target_reviews = [r for r in reviews if r.get("sentiment") == priority_sentiment]
    if not target_reviews:
        target_reviews = reviews  # ìš°ì„ ìˆœìœ„ ê°ì •ì´ ì—†ìœ¼ë©´ ì „ì²´ ì‚¬ìš©
        priority_sentiment = "mixed"
    
    # OpenAI APIë¡œ ë‚´ìš© ë¶„ì„
    api_key = os.getenv("OPENAI_API_KEY")
    print(f"ğŸ”‘ ML ì„œë¹„ìŠ¤: OpenAI API í‚¤ í™•ì¸ - {'ìˆìŒ' if api_key else 'ì—†ìŒ'}")
    
    if not api_key:
        print("âŒ ML ì„œë¹„ìŠ¤: OpenAI API í‚¤ê°€ ì—†ì–´ì„œ ë”ë¯¸ ë°ì´í„° ë°˜í™˜")
        # ë”ë¯¸ ë¶„ì„ ê²°ê³¼
        if priority_sentiment == "positive":
            return {"insight": "ë§›ê³¼ ì„œë¹„ìŠ¤ê°€ ì¢‹ë‹¤ëŠ” í‰ê°€", "keywords": ["ë§›", "ì„œë¹„ìŠ¤"]}
        elif priority_sentiment == "negative":
            return {"insight": "ë§›ì´ë‚˜ ì„œë¹„ìŠ¤ ê°œì„  í•„ìš”", "keywords": ["ê°œì„ í•„ìš”"]}
        else:
            return {"insight": "ë‹¤ì–‘í•œ ì˜ê²¬", "keywords": ["ë³´í†µ"]}
    
    try:
        review_texts = [r.get("text", "")[:150] for r in target_reviews[:8]]  # ìµœëŒ€ 8ê°œ ë¦¬ë·°
        print(f"ğŸ¤– ML ì„œë¹„ìŠ¤: OpenAI API í˜¸ì¶œ ì¤€ë¹„, ëŒ€ìƒ ë¦¬ë·° {len(review_texts)}ê°œ")
        for i, text in enumerate(review_texts[:3]):
            print(f"  ğŸ“„ ë¶„ì„í•  ë¦¬ë·° {i+1}: {text[:50]}...")
        
        sentiment_desc = "ê¸ì •ì ì¸" if priority_sentiment == "positive" else "ë¶€ì •ì ì¸" if priority_sentiment == "negative" else "ì¤‘ë¦½ì ì¸"
        
        prompt = f"""ë‹¤ìŒì€ {menu_name}ì— ëŒ€í•œ {sentiment_desc} ë¦¬ë·°ë“¤ì…ë‹ˆë‹¤. ë¦¬ë·°ì—ì„œ ì‹¤ì œë¡œ ì–¸ê¸‰ëœ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ì¥ë‹˜ì—ê²Œ ë„ì›€ë  í•œì¤„ ìš”ì•½ì„ í•´ì£¼ì„¸ìš”.

ë¦¬ë·°ë“¤:
{chr(10).join([f"- {text}" for text in review_texts])}

ê·œì¹™:
1. ë¦¬ë·°ì—ì„œ ì‹¤ì œë¡œ ì–¸ê¸‰ëœ ë‚´ìš©ë§Œ ì‚¬ìš© (ì¶”ì¸¡ ê¸ˆì§€)
2. 10ì ì´ë‚´ë¡œ ê°„ë‹¨í•˜ê²Œ
3. ë¦¬ë·°ê°€ ë„ˆë¬´ ë‹¨ìˆœí•˜ë©´ "ê³ ê°ë“¤ì´ ì¢‹ì•„í•´ìš”" ìˆ˜ì¤€ìœ¼ë¡œ ê°„ë‹¨íˆ
4. êµ¬ì²´ì  ì–¸ê¸‰ì´ ìˆì„ ë•Œë§Œ êµ¬ì²´ì ìœ¼ë¡œ ("ì§œë‹¤", "ì–‘ì´ ë§ë‹¤", "ë¹ ë¥´ë‹¤" ë“±ì´ ì‹¤ì œ ì–¸ê¸‰ëœ ê²½ìš°)

ìš”ì•½:"""

        print(f"ğŸ“¤ ML ì„œë¹„ìŠ¤: OpenAI API ìš”ì²­ ì‹œì‘")
        print(f"  - í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)}ì")
        
        headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
        data = {
            "model": "gpt-4o-mini",
            "messages": [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë¦¬ë·° ë‚´ìš©ì„ ë¶„ì„í•´ì„œ êµ¬ì²´ì ì¸ íŠ¹ì§•ì„ ì°¾ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.2,
            "max_tokens": 60
        }
        
        resp = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=data, timeout=30)
        print(f"ğŸ“¥ ML ì„œë¹„ìŠ¤: OpenAI API ì‘ë‹µ ìƒíƒœ {resp.status_code}")
        
        if resp.status_code == 200:
            content = resp.json()["choices"][0]["message"]["content"].strip()
            print(f"âœ… ML ì„œë¹„ìŠ¤: OpenAIì—ì„œ ë°›ì€ ì‘ë‹µ: {content}")
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹)
            keywords = []
            keyword_candidates = ["ë§›", "ì–‘", "ê°€ê²©", "ì„œë¹„ìŠ¤", "ë¶„ìœ„ê¸°", "ì¹œì ˆ", "ë¹ ë¦„", "ì‹ ì„ ", "ë”°ëœ»", "ì°¨ê°€ì›€", "ì§œë‹¤", "ë‹¬ë‹¤", "ë§¤ì›€"]
            for keyword in keyword_candidates:
                if keyword in content:
                    keywords.append(keyword)
            
            result = {
                "insight": content[:15],  # ìµœëŒ€ 15ìë¡œ ë‹¨ì¶•
                "keywords": keywords[:3]  # ìµœëŒ€ 3ê°œ í‚¤ì›Œë“œ
            }
            print(f"ğŸ¯ ML ì„œë¹„ìŠ¤: ìµœì¢… ê²°ê³¼ - {result}")
            return result
        else:
            print(f"âŒ ML ì„œë¹„ìŠ¤: OpenAI API ì‘ë‹µ ì‹¤íŒ¨ - {resp.status_code}: {resp.text}")
            
    except Exception as e:
        print(f"âŒ ML ì„œë¹„ìŠ¤: ë¦¬ë·° ë‚´ìš© ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    
    # ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’
    print("ğŸ”„ ML ì„œë¹„ìŠ¤: ê¸°ë³¸ê°’ ë°˜í™˜")
    if priority_sentiment == "positive":
        return {"insight": "ê³ ê°ë“¤ì´ ë§Œì¡±í•´í•©ë‹ˆë‹¤", "keywords": ["ë§Œì¡±"]}
    elif priority_sentiment == "negative":
        return {"insight": "ê°œì„ í•  ì ì´ ìˆì–´ë³´ì…ë‹ˆë‹¤", "keywords": ["ê°œì„ "]}
    else:
        return {"insight": "ë‹¤ì–‘í•œ ì˜ê²¬ì´ ìˆìŠµë‹ˆë‹¤", "keywords": ["ë³´í†µ"]}

@app.post("/api/reviews/comprehensive-insights")
def generate_comprehensive_insights(payload: dict):
    """
    ì „ì²´ ë¦¬ë·° ê¸°ë°˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 3ê°€ì§€ ìƒì„±
    ìš”ì²­: {
      "reviews": [{
        "comment": str,
        "rating": int,
        "nationality": str,
        "menuName": str,
        "createdAt": str
      }],
      "timeRange": str  # "week", "month" ë“±
    }
    ì‘ë‹µ: {
      "insights": [
        {
          "type": "trend|improvement|strength",
          "title": str,
          "description": str,
          "priority": "high|medium|low"
        }
      ]
    }
    """
    reviews = payload.get("reviews", [])
    time_range = payload.get("timeRange", "month")
    
    if len(reviews) < 3:
        return {
            "insights": [
                {
                    "type": "trend",
                    "title": "ë°ì´í„° ë¶€ì¡±",
                    "description": "ë” ë§ì€ ë¦¬ë·°ê°€ í•„ìš”í•´ìš”",
                    "priority": "low"
                }
            ]
        }
    
    # OpenAI APIë¡œ ì¢…í•© ì¸ì‚¬ì´íŠ¸ ìƒì„±
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        # ë”ë¯¸ ì¸ì‚¬ì´íŠ¸ ë°˜í™˜
        return {
            "insights": [
                {
                    "type": "trend",
                    "title": "ì™¸êµ­ì¸ ë¦¬ë·° ì¦ê°€",
                    "description": f"ì´ë²ˆ {get_time_korean(time_range)} ì™¸êµ­ì¸ ë¦¬ë·°ê°€ ëŠ˜ì–´ë‚¬ì–´ìš”",
                    "priority": "high",
                    "suggestedFilters": {"sort": "latest"}
                },
                {
                    "type": "improvement", 
                    "title": "ê°œì„  í¬ì¸íŠ¸ ë°œê²¬",
                    "description": "ì¼ë¶€ ë©”ë‰´ì— ëŒ€í•œ ì•„ì‰¬ìš´ ì˜ê²¬ì´ ìˆì–´ìš”",
                    "priority": "medium",
                    "suggestedFilters": {"sentiment": "negative"}
                },
                {
                    "type": "strength",
                    "title": "ê³ ê° ë§Œì¡±ë„ ì–‘í˜¸",
                    "description": "ì „ë°˜ì ìœ¼ë¡œ ê¸ì •ì ì¸ í‰ê°€ë¥¼ ë°›ê³  ìˆì–´ìš”",
                    "priority": "high",
                    "suggestedFilters": {"sentiment": "positive", "rating": "5"}
                }
            ]
        }
    
    try:
        # ë¦¬ë·° ë°ì´í„° ìš”ì•½ (í† í° ì ˆì•½)
        recent_reviews = reviews[-50:]  # ìµœê·¼ 50ê°œë§Œ ë¶„ì„
        
        # êµ­ê°€ë³„ í†µê³„
        nationality_stats = {}
        rating_stats = {"positive": 0, "neutral": 0, "negative": 0}
        menu_mentions = {}
        
        for review in recent_reviews:
            # êµ­ê°€ë³„ ì§‘ê³„
            nat = review.get("nationality", "ê¸°íƒ€")
            nationality_stats[nat] = nationality_stats.get(nat, 0) + 1
            
            # í‰ì ë³„ ì§‘ê³„
            rating = review.get("rating", 3)
            if rating >= 4:
                rating_stats["positive"] += 1
            elif rating <= 2:
                rating_stats["negative"] += 1
            else:
                rating_stats["neutral"] += 1
            
            # ë©”ë‰´ ì–¸ê¸‰ ì§‘ê³„
            menu = review.get("menuName", "")
            if menu:
                menu_mentions[menu] = menu_mentions.get(menu, 0) + 1
        
        # í†µê³„ ìš”ì•½
        total_reviews = len(recent_reviews)
        top_nationality = max(nationality_stats.items(), key=lambda x: x[1]) if nationality_stats else ("ê¸°íƒ€", 0)
        satisfaction_rate = (rating_stats["positive"] / total_reviews * 100) if total_reviews > 0 else 0
        
        # êµ­ê°€ë³„ í†µê³„ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì‰½ê²Œ ë³€í™˜
        nationality_display = {
            'KR': 'í•œêµ­', 'JP': 'ì¼ë³¸', 'CN': 'ì¤‘êµ­', 'US': 'ë¯¸êµ­', 
            'IT': 'ì´íƒˆë¦¬ì•„', 'FR': 'í”„ë‘ìŠ¤', 'DE': 'ë…ì¼', 'GB': 'ì˜êµ­'
        }
        
        # ê°€ì¥ ë§ì€ êµ­ê°€ì™€ ë‘ ë²ˆì§¸ ë§ì€ êµ­ê°€ ì°¾ê¸°
        sorted_countries = sorted(nationality_stats.items(), key=lambda x: x[1], reverse=True)
        main_country = sorted_countries[0] if sorted_countries else ("KR", 0)
        second_country = sorted_countries[1] if len(sorted_countries) > 1 else None
        
        main_country_display = nationality_display.get(main_country[0], main_country[0])
        
        prompt = f"""í•œêµ­ ë ˆìŠ¤í† ë‘ì˜ ìµœê·¼ ë¦¬ë·° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ì¥ë‹˜ì—ê²Œ ë„ì›€ì´ ë  ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ 3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

** ì‹¤ì œ ë°ì´í„° **
- ì´ ë¦¬ë·°: {total_reviews}ê°œ
- ë§Œì¡±ë„: {satisfaction_rate:.0f}%  
- ì£¼ìš” ê³ ê°: {main_country_display} {main_country[1]}ëª…
- ê¸ì •/ë¶€ì •: {rating_stats["positive"]}ê°œ/{rating_stats["negative"]}ê°œ
- êµ­ê°€ë³„: {', '.join([f"{nationality_display.get(k, k)} {v}ëª…" for k, v in list(nationality_stats.items())[:3]])}

** ë©”ë‰´ë³„ ì–¸ê¸‰ **
{chr(10).join([f"- {r.get('menuName', 'ì•Œìˆ˜ì—†ìŒ')}: {r.get('comment', '')[:30]}... ({r.get('rating', 0)}ì )" for r in recent_reviews[:5]])}

** ì‘ì„± ê·œì¹™ **
1. TREND: ìµœê·¼ ë™í–¥ì´ë‚˜ ë³€í™” (ì˜ˆ: "ì¼ë³¸ ê³ ê° ì¦ê°€", "í‰ì  ìƒìŠ¹")
2. IMPROVEMENT: êµ¬ì²´ì ì¸ ê°œì„ ì  (ì˜ˆ: "ë§¤ìš´ë§› ì¡°ì ˆ", "ì„œë¹„ìŠ¤ ì†ë„")  
3. STRENGTH: í˜„ì¬ ê°•ì  ìœ ì§€ (ì˜ˆ: "ëœì¥ì°Œê°œ ì¸ê¸°", "ì¹œì ˆí•œ ì„œë¹„ìŠ¤")

** í•„í„° ì‚¬ìš© ê°€ëŠ¥ í‚¤ **
- country: êµ­ê°€ (ì˜ˆ: "US", "JP", "CN", "KR", "IT")
- sentiment: ê°ì • ("positive" ë˜ëŠ” "negative")  
- menu: ë©”ë‰´ëª… (ì‹¤ì œ ë©”ë‰´ ì´ë¦„ ì‚¬ìš©)
- rating: í‰ì  (1-5 ìˆ«ì)

** ì œì•½ ì¡°ê±´ **
- ì œëª©: 10ì ì´ë‚´ (ê°„ê²°)
- ì„¤ëª…: 20ì ì´ë‚´ (í•µì‹¬ë§Œ)
- ì‹¤ì œ ë°ì´í„°ì— ê¸°ë°˜í•œ ë‚´ìš©ë§Œ
- í•œêµ­ ìŒì‹ì  ìƒí™©ì— ë§ê²Œ
- suggestedFiltersëŠ” í•´ë‹¹ ì¸ì‚¬ì´íŠ¸ í™•ì¸ì— í•„ìš”í•œ í•„í„°ë§Œ
- IMPROVEMENTì¼ ë•ŒëŠ” ì£¼ë¡œ sentiment: "negative" ì‚¬ìš©
- STRENGTHì¼ ë•ŒëŠ” ì£¼ë¡œ sentiment: "positive" ì‚¬ìš©

JSONë§Œ ì¶œë ¥:
{{"insights": [{{"type": "trend", "title": "ì œëª©", "description": "ì„¤ëª…", "priority": "high", "suggestedFilters": {{"sentiment": "positive", "country": "US"}}}}, ...]}}"""

        headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
        data = {
            "model": "gpt-4o-mini",
            "messages": [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë ˆìŠ¤í† ë‘ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.3,
            "max_tokens": 400
        }
        
        resp = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=data, timeout=30)
        if resp.status_code == 200:
            content = resp.json()["choices"][0]["message"]["content"].strip()
            
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            content = content.strip()
            
            try:
                parsed = _json.loads(content)
                return parsed
            except _json.JSONDecodeError:
                pass
                
    except Exception as e:
        print(f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
    
    # ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ ë°˜í™˜ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ í•„í„° ì œì•ˆ)
    suggested_filters = {}
    if nationality_stats:
        # ê°€ì¥ ë§ì€ êµ­ê°€
        top_country = max(nationality_stats.items(), key=lambda x: x[1])[0]
        suggested_filters["nationality"] = top_country
    
    return {
        "insights": [
            {
                "type": "trend",
                "title": "ë¦¬ë·° í™œë™ ì¦ê°€",
                "description": f"ì´ë²ˆ {get_time_korean(time_range)} ë¦¬ë·°ê°€ ëŠ˜ì–´ë‚¬ì–´ìš”",
                "priority": "high",
                "suggestedFilters": {"sort": "latest"}
            },
            {
                "type": "improvement",
                "title": "ê°œì„  ê¸°íšŒ ë°œê²¬", 
                "description": "ê³ ê° ì˜ê²¬ì„ ë¶„ì„í•´ë³´ì„¸ìš”",
                "priority": "medium",
                "suggestedFilters": {"sentiment": "negative"}
            },
            {
                "type": "strength",
                "title": "ê¸ì • í‰ê°€ ìœ ì§€",
                "description": "ê³ ê°ë“¤ì´ ì „ë°˜ì ìœ¼ë¡œ ë§Œì¡±í•´í•´ìš”",
                "priority": "high",
                "suggestedFilters": {"sentiment": "positive"}
            }
        ]
    }

def get_time_korean(time_range):
    return {"week": "ì£¼", "month": "ë‹¬", "year": "ë…„"}.get(time_range, "ê¸°ê°„")

@app.post("/api/reviews/insights")
def generate_menu_insights(payload: dict):
    """
    ë©”ë‰´ë³„ ë¦¬ë·° ë¶„ì„ í›„ ì‚¬ì¥ë‹˜ìš© ì¸ì‚¬ì´íŠ¸ ìƒì„±
    ìš”ì²­: {
      "menus": [{"menuName": str, "positiveCount": int, "negativeCount": int, "neutralCount": int, "averageRating": float, "reviewSummary": str}]
    }
    ì‘ë‹µ: {
      "insights": [str],  # ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ ë¦¬ìŠ¤íŠ¸
      "recommendations": [str]  # ê°œì„ /í™œìš© ì œì•ˆ
    }
    """
    menus = payload.get("menus", [])
    
    if not menus:
        return {"insights": [], "recommendations": []}
    
    insights = []
    recommendations = []
    
    # ì „ì²´ ë©”ë‰´ ë¶„ì„
    total_positive = sum(m.get("positiveCount", 0) for m in menus)
    total_negative = sum(m.get("negativeCount", 0) for m in menus)
    total_reviews = total_positive + total_negative + sum(m.get("neutralCount", 0) for m in menus)
    
    # ì¸ì‚¬ì´íŠ¸ 1: ì „ì²´ ë§Œì¡±ë„
    if total_reviews > 0:
        satisfaction_rate = (total_positive / total_reviews) * 100
        if satisfaction_rate >= 80:
            insights.append(f"ê³ ê° ë§Œì¡±ë„ê°€ {satisfaction_rate:.0f}%ë¡œ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤")
        elif satisfaction_rate >= 60:
            insights.append(f"ê³ ê° ë§Œì¡±ë„ëŠ” {satisfaction_rate:.0f}%ë¡œ ì–‘í˜¸í•œ í¸ì…ë‹ˆë‹¤")
        else:
            insights.append(f"ê³ ê° ë§Œì¡±ë„ê°€ {satisfaction_rate:.0f}%ë¡œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤")
    
    # ì¸ì‚¬ì´íŠ¸ 2: ìµœê³ /ìµœì € í‰ì  ë©”ë‰´
    if len(menus) > 1:
        best_menu = max(menus, key=lambda x: x.get("averageRating", 0))
        worst_menu = min(menus, key=lambda x: x.get("averageRating", 0))
        
        if best_menu.get("averageRating", 0) >= 4.0:
            insights.append(f"'{best_menu.get('menuName', '')}'ì´ ê°€ì¥ ì¸ê¸° ë©”ë‰´ì…ë‹ˆë‹¤")
            recommendations.append(f"'{best_menu.get('menuName', '')}'ì„ ë©”ì¸ ë©”ë‰´ë¡œ í™ë³´í•˜ì„¸ìš”")
        
        if worst_menu.get("averageRating", 0) <= 3.0:
            insights.append(f"'{worst_menu.get('menuName', '')}'ì€ ê°œì„ ì´ í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤")
            recommendations.append(f"'{worst_menu.get('menuName', '')}'ì˜ ë ˆì‹œí”¼ë‚˜ ê°€ê²©ì„ ê²€í† í•´ë³´ì„¸ìš”")
    
    # ì¸ì‚¬ì´íŠ¸ 3: ë¶€ì • ë¦¬ë·°ê°€ ë§ì€ ë©”ë‰´
    negative_menus = [m for m in menus if m.get("negativeCount", 0) > m.get("positiveCount", 0)]
    if negative_menus:
        menu_names = [m.get("menuName", "") for m in negative_menus[:2]]
        insights.append(f"{', '.join(menu_names)}ì— ëŒ€í•œ ë¶ˆë§Œì´ ìˆì–´ ë³´ì…ë‹ˆë‹¤")
        recommendations.append("ë¶€ì •ì ì¸ ë¦¬ë·°ì˜ êµ¬ì²´ì ì¸ ë‚´ìš©ì„ í™•ì¸í•´ë³´ì„¸ìš”")
    
    # ì¸ì‚¬ì´íŠ¸ 4: ë¦¬ë·°ê°€ ì ì€ ë©”ë‰´
    low_review_menus = [m for m in menus if (m.get("positiveCount", 0) + m.get("negativeCount", 0) + m.get("neutralCount", 0)) < 3]
    if low_review_menus:
        menu_names = [m.get("menuName", "") for m in low_review_menus[:2]]
        insights.append(f"{', '.join(menu_names)}ëŠ” ì•„ì§ ë¦¬ë·°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤")
        recommendations.append("ì‹ ë©”ë‰´ë‚˜ í™ë³´ê°€ ë¶€ì¡±í•œ ë©”ë‰´ëŠ” ì ê·¹ì ìœ¼ë¡œ ì¶”ì²œí•´ë³´ì„¸ìš”")
    
    return {
        "insights": insights[:4],  # ìµœëŒ€ 4ê°œ ì¸ì‚¬ì´íŠ¸
        "recommendations": recommendations[:3]  # ìµœëŒ€ 3ê°œ ì¶”ì²œì‚¬í•­
    }

@app.post("/api/reviews/keywords")
def extract_review_keywords(payload: dict):
    """
    ìš”ì²­: {
      "comments": [{"text": str, "rating": int, "menuIdx": int, "language": str|null}],
      "positiveThreshold": 4,
      "negativeThreshold": 2,
      "topK": 5
    }
    ì‘ë‹µ: {
      "overall": {"positiveKeywords": [], "negativeKeywords": []},
      "byMenu": [{"menuIdx": int, "positiveKeywords": [], "negativeKeywords": []}]
    }
    """
    comments = payload.get("comments", [])
    pos_th = int(payload.get("positiveThreshold", 4))
    neg_th = int(payload.get("negativeThreshold", 2))
    top_k = int(payload.get("topK", 5))

    def tokenize(text: str):
        if not text:
            return []
        # ì•„ì£¼ ë‹¨ìˆœ í† í¬ë‚˜ì´ì§•: ì˜/í•œ/ìˆ«ìë§Œ ë‚¨ê¸°ê³  ê³µë°± ë¶„ë¦¬
        cleaned = _re.sub(r"[^0-9A-Za-zê°€-í£\s]", " ", text)
        tokens = [t.strip().lower() for t in cleaned.split() if len(t.strip()) >= 2]
        return tokens

    def top_keywords(texts):
        counter = Counter()
        for t in texts:
            counter.update(tokenize(t))
        return [w for w, _ in counter.most_common(top_k)]

    pos_texts = [c.get("text", "") for c in comments if (c.get("rating") or 0) >= pos_th]
    neg_texts = [c.get("text", "") for c in comments if (c.get("rating") or 0) <= neg_th]

    mode = (payload.get("mode") or "simple").lower()

    if mode == "openai":
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            try:
                # ì…ë ¥ ì¶•ì•½ (í† í° í­ì£¼ ë°©ì§€)
                def sample_texts(texts, limit=50, each_len=120):
                    return [t[:each_len] for t in texts[:limit]]

                prompt = {
                    "instruction": (
                        "Given review texts grouped by positive and negative (and by menuIdx), "
                        "extract top unique keywords only (no sentences), prioritize aspect terms and nouns, "
                        "deduplicate similar words, and return exactly the following JSON schema without extra text: "
                        "{\"overall\": {\"positiveKeywords\": [], \"negativeKeywords\": []}, \"byMenu\": [{\"menuIdx\": 0, \"positiveKeywords\": [], \"negativeKeywords\": []}]}"
                    ),
                    "topK": top_k,
                    "overall": {
                        "positiveTexts": sample_texts(pos_texts),
                        "negativeTexts": sample_texts(neg_texts),
                    },
                    "byMenu": {}
                }
                # byMenu í…ìŠ¤íŠ¸ êµ¬ì„±
                by_menu_texts = {}
                for c in comments:
                    mi = c.get("menuIdx")
                    if mi is None:
                        continue
                    r = int(c.get("rating") or 0)
                    entry = by_menu_texts.setdefault(mi, {"pos": [], "neg": []})
                    (entry["pos"] if r >= pos_th else entry["neg"] if r <= neg_th else entry.setdefault("neu", [])).append((c.get("text") or "")[:120])
                prompt["byMenu"] = {str(k): {"positiveTexts": v.get("pos", []), "negativeTexts": v.get("neg", [])} for k, v in by_menu_texts.items()}

                headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
                data = {
                    "model": "gpt-4o-mini",
                    "messages": [
                        {"role": "system", "content": "You are a precise NLP assistant for keyword extraction. Output strictly valid JSON only."},
                        {"role": "user", "content": _json.dumps(prompt, ensure_ascii=False)}
                    ],
                    "temperature": 0.2,
                    "max_tokens": 400
                }
                resp = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=data, timeout=30)
                if resp.status_code == 200:
                    content = resp.json()["choices"][0]["message"]["content"].strip()
                    try:
                        parsed = _json.loads(content)
                        # ìµœì†Œ ìœ íš¨ì„± ê²€ì‚¬ ë° topK ì œí•œ
                        def clamp(arr):
                            if isinstance(arr, list):
                                return [str(x)[:40] for x in arr][:top_k]
                            return []
                        overall = {
                            "positiveKeywords": clamp(parsed.get("overall", {}).get("positiveKeywords", [])),
                            "negativeKeywords": clamp(parsed.get("overall", {}).get("negativeKeywords", [])),
                        }
                        by_menu = []
                        for item in parsed.get("byMenu", []):
                            by_menu.append({
                                "menuIdx": int(item.get("menuIdx", 0)),
                                "positiveKeywords": clamp(item.get("positiveKeywords", [])),
                                "negativeKeywords": clamp(item.get("negativeKeywords", [])),
                            })
                        return {"overall": overall, "byMenu": by_menu}
                    except Exception:
                        pass
            except Exception:
                pass

    overall = {
        "positiveKeywords": top_keywords(pos_texts),
        "negativeKeywords": top_keywords(neg_texts),
    }

    # ë©”ë‰´ë³„
    by_menu_map = {}
    for c in comments:
        menu_idx = c.get("menuIdx")
        if menu_idx is None:
            continue
        m = by_menu_map.setdefault(menu_idx, {"pos": [], "neg": []})
        rating = c.get("rating") or 0
        if rating >= pos_th:
            m["pos"].append(c.get("text", ""))
        elif rating <= neg_th:
            m["neg"].append(c.get("text", ""))

    by_menu = []
    for k, v in by_menu_map.items():
        by_menu.append({
            "menuIdx": k,
            "positiveKeywords": top_keywords(v.get("pos", [])),
            "negativeKeywords": top_keywords(v.get("neg", [])),
        })

    return {"overall": overall, "byMenu": by_menu}

# í™˜ê²½ë³€ìˆ˜ë¡œ ì¸ì¦ ì„¤ì • (ì„ íƒì‚¬í•­)
google_credentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
if google_credentials_path and os.path.exists(google_credentials_path):
    print(f"Google Cloud credentials loaded from: {google_credentials_path}")
elif google_credentials_path:
    print(f"Google Cloud credentials path set but file not found: {google_credentials_path}")
else:
    print("Warning: Google Cloud credentials not found - OCR/Translation features may not work")

# íŠ¹ì¼ - ê³ ê° ë§¤ì¹­
@app.post("/api/match/specialDay")
def specialDay_match(request: SpecialDayMatchRequest):
    """ íŠ¹ì¼ - ê³ ê° ë°ì´í„° ë§¤ì¹­"""
    result = []
    for i, day in enumerate(request.specialDays):
        # llama ëª¨ë¸ë¡œ íŒë‹¨
        judgement = MatchModels.specialDay_model(day.name, request.matchRequest.storeCategory)

        if judgement == 1:
            result.append({
                 "sd_idx": day.sd_idx,
                 "userId": request.matchRequest.userId
            })

    return result

# íŠ¹ì¼ ì»¨í…ì¸  ìƒì„±
@app.post("/api/content/generate")
def generate_content(request: ContentGenerationRequest):
    """ íŠ¹ì¼ ì»¨í…ì¸  ìƒì„± """
    try:
        content = ContentService.generate_special_day_content(
            name=request.name,
            type_name=request.type,
            category=request.category
        )
        
        return {
            "success": True,
            "content": content
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì»¨í…ì¸  ìƒì„± ì‹¤íŒ¨: {str(e)}")

# íŠ¹ì¼ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
@app.post("/api/category/classify")
def classify_categories(request: CategoryClassificationRequest):
    """ íŠ¹ì¼ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ """
    try:
        categories = CategoryService.classify_special_day_categories(
            name=request.name,
            type_name=request.type,
            category=request.category
        )
        
        return {
            "success": True,
            "categories": categories
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
    
# íŠ¹ì¼ ì œì•ˆ ìƒì„±
@app.post("/api/suggest/create")
def create_suggest(request: CreateSuggestRequest):
    """ íŠ¹ì¼ ì œì•ˆ ìƒì„± """
    try:
        result = ContentService.create_special_day_suggest(
            name=request.name,
            type_name=request.type,
            storeCategory=request.storeCategory
        )
        
        # ê³„ì‚°ëœ confidenceë¥¼ ì§ì ‘ ì‚¬ìš© (ë¬¸ìì—´ì´ ì•„ë‹Œ ìˆ«ì)
        calculated_confidence = ContentService.calculate_confidence(
            request.name, request.type, request.storeCategory
        )
        
        return {
            "success": True,
            "title": result.title,
            "description": result.description,
            "targetCustomer": result.targetCustomer,
            "suggestedAction": result.suggestedAction,
            "expectedEffect": result.expectedEffect,
            "confidence": calculated_confidence,  # ìˆ«ìê°’ ì§ì ‘ ì‚¬ìš©
            "priority": result.priority
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.post("/api/ocr")
async def extract_text(file: UploadFile = File(...)):

    # Google Cloud ì¸ì¦ì´ ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„° ë°˜í™˜
    google_credentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
    if not google_credentials_path or not os.path.exists(google_credentials_path):
        # ë”ë¯¸ OCR ê²°ê³¼ ë°˜í™˜
        return [
            MenuItem(menuName="ëœì¥ì°Œê°œ", menuPrice=7000),
            MenuItem(menuName="ê¹€ì¹˜ì°Œê°œ", menuPrice=7500), 
            MenuItem(menuName="ì œìœ¡ë³¶ìŒ", menuPrice=8000),
            MenuItem(menuName="ë¶ˆê³ ê¸°", menuPrice=9000)
        ]

    try:
        # íŒŒì¼ íƒ€ì… ê²€ì¦
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        
        # íŒŒì¼ í¬ê¸° ì œí•œ (ì˜ˆ: 10MB)
        contents = await file.read()
        if len(contents) > 10 * 1024 * 1024:
            raise HTTPException(status_code=413, detail="íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤")
        
        # OCR ì²˜ë¦¬
        client = vision.ImageAnnotatorClient()
        image = vision.Image(content=contents)
        response = client.document_text_detection(image=image)
        document = response.full_text_annotation
        # ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ì¶œë ¥ + ì¢Œí‘œ ì •ë³´ ì¶œë ¥
        for page in document.pages:
            for block in page.blocks:
                block_text = ''
                for paragraph in block.paragraphs:
                    for word in paragraph.words:
                        word_text = ''.join([symbol.text for symbol in word.symbols])
                        block_text += word_text + ' '
                    block_text += '\n'

                # ë¸”ë¡ ì¢Œí‘œ ê°€ì ¸ì˜¤ê¸° (bounding boxì˜ ê¼­ì§“ì  4ê°œ)
                vertices = block.bounding_box.vertices
                coords = [(v.x, v.y) for v in vertices]

                # ì¶œë ¥
                print("ë¬¸ë‹¨ í…ìŠ¤íŠ¸:")
                print(block_text.strip())
                print("ë¬¸ë‹¨ ì¢Œí‘œ (bounding box):", coords)
                print("-" * 50)

        texts = response.text_annotations
        text = texts[0].description
        
        items = []
        lines = text.strip().split('\n')
        
        # í™•ì¥ëœ ê°€ê²© íŒ¨í„´ë“¤
        price_patterns = [
            r'(\d{1,3}[,.]?\d{3})\s*ì›',  # 16,000ì›
            r'(\d{1,3}[,.]?\d{3})',       # 16,000
            r'(\d{4,6})',                 # 16000
            r'(\d+\.\d)',                 # 5.0
        ]
     
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            # ë¹ˆ ì¤„ ìŠ¤í‚µ
            if not line:
                i += 1
                continue
            
            # ë…¸ì´ì¦ˆ í•„í„°ë§ (ì´ë©”ì¼, ì „í™”ë²ˆí˜¸, ì£¼ì†Œ, ì‹œê°„ ë“±)
            if (re.search(r'@.*\.com', line) or 
                re.search(r'\+?\d{3}-\d{3}-\d{4}', line) or
                re.search(r'\d+\s+anywhere', line.lower()) or
                re.search(r'\d{1,2}[:.]\d{2}\s*(am|pm)', line.lower()) or
                len([c for c in line if c.isalpha()]) < 2):  # ë„ˆë¬´ ì ì€ ë¬¸ì
                i += 1
                continue
            
            # í˜„ì¬ ì¤„ì—ì„œ ê°€ê²© ì°¾ê¸°
            price_found = False
            for pattern in price_patterns:
                price_match = re.search(pattern, line)
                if price_match:
                    try:
                        price_str = price_match.group(1).replace(',', '').replace('.', '')
                        
                        # ì†Œìˆ˜ì  í˜•íƒœ ì²˜ë¦¬ (5.0 -> 5000)
                        if '.' in price_match.group(1) and len(price_str) <= 2:
                            price = int(float(price_match.group(1)) * 1000)
                        else:
                            price = int(price_str)
                        
                        # í•©ë¦¬ì ì¸ ê°€ê²© ë²”ìœ„ ì²´í¬
                        if 1000 <= price <= 50000:
                            menu_name = line[:price_match.start()].strip()
                            if menu_name and len(menu_name) > 1:
                                items.append(MenuItem(menuName=menu_name, menuPrice=price))
                                price_found = True
                                break
                    except ValueError:
                        continue
            
            if not price_found:
                # í˜„ì¬ ì¤„ì— ê°€ê²©ì´ ì—†ìœ¼ë©´ ë‹¤ìŒ ì¤„ í™•ì¸
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    
                    for pattern in price_patterns:
                        next_price_match = re.search(pattern, next_line)
                        if next_price_match:
                            try:
                                price_str = next_price_match.group(1).replace(',', '').replace('.', '')
                                
                                # ì†Œìˆ˜ì  í˜•íƒœ ì²˜ë¦¬
                                if '.' in next_price_match.group(1) and len(price_str) <= 2:
                                    price = int(float(next_price_match.group(1)) * 1000)
                                else:
                                    price = int(price_str)
                                
                                # í•©ë¦¬ì ì¸ ê°€ê²© ë²”ìœ„ ì²´í¬
                                if 1000 <= price <= 50000:
                                    # ë‹¤ìŒ ì¤„ì´ ìˆœìˆ˜ ê°€ê²©ì¸ì§€ í™•ì¸ (ì› ë¬¸ì í¬í•¨í•´ì„œ ì²˜ë¦¬)
                                    remaining_text = next_line.replace(next_price_match.group(0), '').replace('ì›', '').strip()
                                    
                                    # ë‚¨ì€ í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ìœ¼ë©´ ìˆœìˆ˜ ê°€ê²©ìœ¼ë¡œ íŒë‹¨
                                    if len(remaining_text) <= 2:
                                        # ì—­ë°©í–¥ìœ¼ë¡œ ì§„ì§œ ë©”ë‰´ëª… ì°¾ê¸°
                                        menu_name = line
                                        # í˜„ì¬ ì¤„ì´ ì„¤ëª…ë¬¸ì¸ì§€ í™•ì¸ (ì‰¼í‘œ, ë§ˆì¹¨í‘œ í¬í•¨ ë˜ëŠ” 15ê¸€ì ì´ˆê³¼)
                                        if (',' in line or '.' in line or len(line) > 15):
                                            
                                            # ìµœëŒ€ 3ì¤„ ì „ê¹Œì§€ í™•ì¸
                                            for back_offset in range(1, min(4, i + 1)):
                                                prev_line = lines[i - back_offset].strip()
                                                
                                                # ì´ì „ ì¤„ì´ ì„¤ëª…ë¬¸ì´ ì•„ë‹ˆê³  ê°€ê²©ì´ ì—†ìœ¼ë©´ ë©”ë‰´ëª… ê°€ëŠ¥ì„± ë†’ìŒ
                                                if (prev_line and 
                                                    not (',' in prev_line or '.' in prev_line or len(prev_line) > 15) and
                                                    not re.search(r'\d+[,.]?\d*ì›?', prev_line)):  # ê°€ê²©ì´ ì—†ê³ 
                                                    menu_name = prev_line
                                                    break
                                    
                                        if len(menu_name) > 1:
                                            items.append(MenuItem(menuName=menu_name, menuPrice=price))
                                            i += 1  # ë‹¤ìŒ ì¤„ ìŠ¤í‚µ
                                            break
                            except ValueError:
                                continue
            
            i += 1

        return items
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/translate")
def translateMenu(req: TranslateRequest):
    # ìš”ì²­ ë°›ì€ ë©”ë‰´ëª…
    source_text = req.text
    targetLanguage = req.targetLanguage
    # ë²ˆì—­ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    translate_client = translate.Client()
    # ë²ˆì—­ ì‹¤í–‰
    result = translate_client.translate(
        source_text,
        target_language= targetLanguage  
    )

    return {
        "targetLanguage": targetLanguage,
        "translated": result["translatedText"]
    }

@app.post("/api/translateWeb")
def translate_text(req: TranslateRequest2):
    try:
        translate_client = translate.Client()
        all_translated_texts = []
        
        # API í—ˆìš© ìµœëŒ€ í…ìŠ¤íŠ¸ ìˆ˜
        MAX_TEXT_SEGMENTS = 128
        # í…ìŠ¤íŠ¸ ë°°ì—´ì„ ìµœëŒ€ í—ˆìš© ìˆ˜ë§Œí¼ ë¬¶ìŒìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
        num_chunks = math.ceil(len(req.texts) / MAX_TEXT_SEGMENTS)
        
        for i in range(num_chunks):
            start_index = i * MAX_TEXT_SEGMENTS
            end_index = start_index + MAX_TEXT_SEGMENTS
            chunk_of_texts = req.texts[start_index:end_index]
            
            # ê° ë¬¶ìŒì„ ë³„ë„ì˜ API ìš”ì²­ìœ¼ë¡œ ë³´ëƒ…ë‹ˆë‹¤.
            results = translate_client.translate(chunk_of_texts, target_language=req.targetLanguage)
            translated_chunk = [result["translatedText"] for result in results]
            all_translated_texts.extend(translated_chunk)
            
        return {"translated_texts": all_translated_texts}
    
    except Exception as e:
        print(f"An error occurred: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/reviews/translate")
def translate_reviews(req: ReviewTranslateRequest):
    """
    ë¦¬ë·° ë‚´ìš©ë“¤ì„ ì¼ê´„ ë²ˆì—­
    """
    try:
        translate_client = translate.Client()
        
        # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë‚˜ None ì²´í¬
        if not req.reviews:
            return {"translated_reviews": []}
        
        # ë¹ˆ ë¬¸ìì—´ í•„í„°ë§
        filtered_reviews = [review for review in req.reviews if review and review.strip()]
        if not filtered_reviews:
            return {"translated_reviews": [""] * len(req.reviews)}
        
        # ì²­í¬ ë‹¨ìœ„ë¡œ ë²ˆì—­ (Google Translate API ì œí•œ ê³ ë ¤)
        chunk_size = 100
        all_translated_reviews = []
        
        for i in range(0, len(filtered_reviews), chunk_size):
            chunk_of_reviews = filtered_reviews[i:i + chunk_size]
            results = translate_client.translate(chunk_of_reviews, target_language=req.targetLanguage)
            # ë²ˆì—­ ê²°ê³¼ì—ì„œ ì•ë’¤ ê³µë°± ë° ê°œí–‰ ë¬¸ì ì œê±°
            translated_chunk = [result["translatedText"].strip() for result in results]
            all_translated_reviews.extend(translated_chunk)
            
        # ì›ë³¸ê³¼ ê°™ì€ ê¸¸ì´ë¡œ ë§ì¶¤ (ë¹ˆ ë¬¸ìì—´ ìœ„ì¹˜ ë³µì›)
        result_reviews = []
        translated_idx = 0
        for original_review in req.reviews:
            if original_review and original_review.strip():
                result_reviews.append(all_translated_reviews[translated_idx])
                translated_idx += 1
            else:
                result_reviews.append("")
        
        return {"translated_reviews": result_reviews}
    
    except Exception as e:
        print(f"ë¦¬ë·° ë²ˆì—­ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë²ˆì—­ ì‹¤íŒ¨: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app, 
        host=API_CONFIG["host"], 
        port=API_CONFIG["port"]

    ) 
